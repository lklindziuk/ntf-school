{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Revealing mesocale structures of time-varying networks through non-negative tensor factorization\n",
    "\n",
    "In this notebook we show how the method presented in [[1]](#1) can be applied to data about face-to-face proximity relations collected in a school.\n",
    "\n",
    "The data were collected by the [SocioPatterns collaboration](http://www.sociopatterns.org) using wearable proximity sensors that sense the face-to-face proximity relations of individuals wearing them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few libraries are required in order to run this notebook. The Python Pandas library is used for data loading and manipulation, the `sktensor` library is used to represent the 3-way tensors and the `ncp` script contains the algorithms for the non-negative tensor factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "\n",
    "import pandas as pd\n",
    "import sktensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ncp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we load the expected structures (classes) that are used as a validation for the methodology.\n",
    "\n",
    "The population of the school consisted of 231 children, organized in 10 classes, and 10 teachers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_csv(\"data/classes.csv\", index_col=0, squeeze=True)\n",
    "print(classes.size)\n",
    "print(classes.unique() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected through the SocioPatterns platorm is represented as triples $<t, i, j>$ where $i,j$ is a pair of nodes that were in proximity during the interval between time $t$ and $t+20$.\n",
    "\n",
    "It represents 2 days of activity in a school. We selected only the hours when the kids were at school, for a total of 18 hours (two intervals of 9 hours per day concatenated as a single interval, thus removing the night)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/school.csv.gz\", compression=\"gzip\")\n",
    "print(data.head())\n",
    "print(data.tail())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data.t.max() / 3600., \"hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the timeline that shows the sum of number of contacts for each 20 seconds interval, we see that there is a small interval with no activity between the two 9 hours interval, in order to show where one day ends and starts the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(data.t).t.count().plot(linestyle='None', marker='.', figsize=(15,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_NODES = classes.index.unique().shape[0]\n",
    "NR_INTERVALS = 150\n",
    "\n",
    "print(NR_NODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this experiment, we divide the timeline in 150 different intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binned = data.groupby((data.t / ((data.t.max()+1) / float(NR_INTERVALS))).astype(int))\n",
    "print(data_binned.head(20))\n",
    "#print(data_binned.shape) #get error\n",
    "\n",
    "#NOT SURE WHAT THIS DOES, BINS WHAT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adj(g):\n",
    "    return g.groupby(['i', 'j']).size()\n",
    "\n",
    "school_adj_series = data_binned.apply(create_adj)\n",
    "school_adj_series.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the $<t, i, j>$ triples in a 3-way binary tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = array([(i, j, t) for t, i, j in school_adj_series.keys()] + \n",
    "                [(j, i, t) for t, i, j in school_adj_series.keys()])\n",
    "\n",
    "print(triples[1:10], triples[-10:-1])\n",
    "\n",
    "X = sktensor.sptensor(tuple(triples.T), ones(len(triples)),\n",
    "                      shape=(NR_NODES, NR_NODES, NR_INTERVALS))\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor is factorized using the alternating non-negative least squares algorithm with the block principal pivoting method, proposed in [[2]](#2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ffd11a9ec0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_approx_ks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mncp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonnegative_tensor_factorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'anls_bpp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "X_approx_ks = ncp.nonnegative_tensor_factorization(X, 14, method='anls_bpp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nWay = len(X.shape)\n",
    "print(nWay)\n",
    "\n",
    "orderWays = np.arange(nWay)\n",
    "print(orderWays)\n",
    "\n",
    "print(range(nWay))\n",
    "print('Finit = F_cell = (241,14), (241,14), (150, 14)')\n",
    "\n",
    "Finit = [np.random.rand(X.shape[i], 14) for i in range(nWay)]\n",
    "F_cell = Finit\n",
    "\n",
    "print('what is inputted into getGradient(X, F_cell=random nums btw 0,1 is specific shape, nWay=3, r=14)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = range(nWay)\n",
    "print(ways)\n",
    "\n",
    "    \n",
    "#for i in [0, 1, 2, 3]:\n",
    "#    print(i)\n",
    "\n",
    "#for i in range(nWay):\n",
    "#    print(i)\n",
    "    \n",
    "def gG(nWay):\n",
    "    for k in range(nWay):\n",
    "        ways2 = [i for i in range(nWay) if i != k] \n",
    "        print(ways2)\n",
    "        #for i in ways:\n",
    "        #    print(i)\n",
    "        \n",
    "gG(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the factorization is a set of loading matrices $\\mathbf{A, B, C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = X_approx_ks.U[0]\n",
    "B = X_approx_ks.U[1]\n",
    "C = X_approx_ks.U[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then group the rows of $\\mathbf{A}$ by class and sum the values, in order to check how much of each class is represented in each one of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame(A).groupby(classes).sum()\n",
    "dfa = dfa[dfa.index!='teachers']\n",
    "\n",
    "plt.pcolormesh(dfa.values, cmap=plt.cm.Greys)\n",
    "plt.xlim(0, dfa.shape[1])\n",
    "plt.yticks(arange(10)+0.5, dfa.index)\n",
    "plt.xticks(arange(14)+0.5, arange(1,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activity timeline of each factor is represented in $\\mathbf{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,4))\n",
    "plt.pcolormesh(C.T, cmap=plt.cm.Greys)\n",
    "plt.xlim(0,C.shape[0])\n",
    "plt.yticks(arange(14)+0.5, arange(1,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reorder the factors to show better the results of the factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_order = [1, 0, 7, 5, 3, 8, 12, 2, 11, 4, 6, 13, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame(A).groupby(classes).sum()\n",
    "dfa = dfa[dfa.index!='teachers']\n",
    "\n",
    "figure()\n",
    "plt.pcolormesh(dfa.values[:, factor_order], cmap=plt.cm.Greys)\n",
    "plt.xlim(0, dfa.shape[1])\n",
    "plt.yticks(arange(10)+0.5, dfa.index)\n",
    "plt.xticks(arange(14)+0.5, arange(1,15));\n",
    "\n",
    "figure(figsize=(10,4))\n",
    "plt.pcolormesh(C[:, factor_order[::-1]].T, cmap=plt.cm.Greys)\n",
    "plt.xlim(0, C.shape[0])\n",
    "plt.yticks(arange(14)+0.5, arange(14,0,-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "<a name=\"1\"></a>[1] L. Gauvin, A. Panisson, C. Cattuto. [Detecting the Community Structure and Activity Patterns of Temporal Networks: A Non-Negative Tensor Factorization Approach](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0086028#pone-0086028-g001) PLOS ONE 9.1 (2014): e86028.\n",
    "\n",
    "<a name=\"2\"></a> [2] Kim J, Park H (2012) Fast nonnegative tensor factorization with an active-set-like method. In: Berry MW, Gallivan KA, Gallopoulos E, Grama A, Philippe B, et al., editors, High-Performance Scientific Computing, Springer London. 311â€“326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
